<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title># 机器学习,机器学习</title>
    <link rel="stylesheet" href="../../assets/css/notes.min.css">
</head>
<body>
    <div id="header-placeholder"></div>
    <div class="main-content-wrapper">
        <main class="content">
            <h1>机器学习</h1>
<h2>1.学习形式</h2>
<p>学习：让 Agent 能应对真实的场景，通过学习修改 Agent 的决策行为，提高性能</p>
<p>学习需要考虑的四个要素：</p>
<ul>
<li>要改进 Agent 的哪个部件
<ul>
<li>条件到动作的直接映射</li>
<li>从感知序列推演状态的映射</li>
<li>动作转移函数</li>
<li>效用函数</li>
<li>动作代价函数</li>
</ul>
</li>
<li>学习具备哪些先验知识
<ul>
<li>归纳学习：从特定的输入输出对中学习一般化的函数和规则，逻辑上并不可靠</li>
<li>分析学习或演绎学习：从已知规则出发，推理出其逻辑蕴含的新规则，提高系统处理的效率</li>
</ul>
</li>
<li>数据和你学习改进的部件如何表示</li>
<li>用于学习的反馈有哪些
<ul>
<li>无监督学习：不提供显式反馈，Agent 学习输入中的模式，目标是发现输入数据的关联或规律，输出往往是数据的另一种表示，例如：聚类</li>
<li>监督学习：Agent 观察某些“输入-输出”对，学习从输入到输出的映射函数，以“输出”作为“输入”的反馈输出是什么取决于学习任务是什么，类比“有参考答案的学习”</li>
<li>强化学习：Agent 在强化序列（奖赏和惩罚组合的序列）中学习，反馈是当前与预期结果的差异，根据对局过程改进博弈，类比在“实践中学习”</li>
</ul>
</li>
</ul>
<h2>2.监督学习</h2>
<p>最简单的形式：从例子中学习映射函数</p>
<p>𝑓 为学习的目标函数：分类（输出 y 的值域是有限集合，最简单的二分类是输出两个可能值）；回归（输出 y 的值域是连续数值的集合）</p>
<p>样例： (𝑥1, 𝑦1), (𝑥2, 𝑦2), …, (𝑥_𝑛, 𝑦_𝑛)，满足函数 y = 𝑓(𝑥)</p>
<p>目标：找到一个函数 ℎ, 使得 ℎ 尽可能逼近 𝑓</p>
<p>由于我们不知道真实函数，所以我们并不总能确定给定的学习问题是否可实现</p>
<p>假说空间 H：用于逼近 𝑓 的一组函数集合，例如，𝐬𝐢𝐧⁡(𝒘𝒙), 𝒂𝒙𝟓+𝒃𝒙𝟐+𝒄𝒙+𝒅</p>
<p>训练集：用于求解 𝒉</p>
<p>测试集：用于评测求解得到的 𝒉</p>
<p>泛化：能够对新的样例进行预测</p>
<p>奥坎姆剃刀：如无必要，勿增实体。如果两个或多个处于竞争地位的理论能得出同样的结论，那么简单或可证伪的那个更好</p>
<h2>3.学习决策树</h2>
<h3>3.1 决策树</h3>
<ul>
<li>输入：属性值向量</li>
<li>输出：决策（分类）结果</li>
<li>输入和输出可以是离散的，也可以是连续的</li>
</ul>
<h3>3.2 从样例归纳决策树</h3>
<p>基本思想：</p>
<ul>
<li>贪婪+分治+递归</li>
<li>总是优先测试最重要属性，将该属性的测试作为当前问题的决策树的根</li>
<li>对该属性的测试将问题分解成更小的子问题</li>
<li>递归解决子问题，构建子决策树</li>
</ul>
<h3>3.3 选择测试属性</h3>
<ul>
<li>熵是随机变量的不确定性度量，信息增加导致熵的减少</li>
<li>设随机变量 𝑽 的取值为 𝒗𝒌 的概率为 𝑷(𝒗𝒌)，则 𝑽 的熵为 $H(V)=\sum_kP(v_i)\mathrm{log}_2\frac1{P(v_i)}=-\sum_kP(v_i)\mathrm{log}_2P(v_i)$</li>
<li>设布尔随机变量以 𝒒 的概率为真，则该变量的熵为 $B(q)=-(q\log_2q+(1-q)\log_2(1-q))$</li>
<li>如果训练集包含 𝑝 个正例和 𝑛 个反例，则目标属性 𝐺𝑜𝑎𝑙 在整个样例集上的熵是 $H(Goal)=B\left(\frac p{p+n}\right)$</li>
<li>测试某个属性 𝐴 后，目标属性的熵会减少，减少的幅度可以作为选择测试属性的依据</li>
<li>例子：以公平(Fair)的方式抛掷一枚硬币，正面向上或反面向上（0 或者 1）的可能性近似相同：$H(Fair)=-(0.5\log_20.5+0.5\log_20.5)=1$</li>
</ul>
<h3>3.4 泛化与过度拟合</h3>
<ul>
<li>过度拟合：模型与训练数据的一致性高，但在测试数据上性能降低</li>
<li>当假说空间和属性数目增长时，过度拟合更可能出现，而随着训练样例的增加，过度拟合的可能性逐步降低</li>
<li>决策树剪枝：减轻对训练样例的过度拟合，删除不明显相关的节点来实现剪枝</li>
</ul>

        </main>
    </div>
    <footer class="footer">
        <p>&copy; 2024 waiwai24. All rights reserved.</p>
    </footer>
    <script src="../../assets/js/header.js"></script>
    <script src="../../assets/js/include-header.js"></script>
</body>
</html>