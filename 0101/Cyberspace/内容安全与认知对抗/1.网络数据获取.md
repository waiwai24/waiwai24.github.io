# 网络数据获取

## 1.数据采集原理

数据采集限制：《数据安全法》

* 遵守robots协议
* 采集公开信息，非商业用途
* 不影响网站正常运行

自动采集过程就是不断调用采集器：**读取链接->下载网页->解析字段->存储数据**



## 2.网页获取

### 2.1 web协议解析

在解析网页数据报文基础上，构造网络报文，发起请求进而获得目标服务器的响应

requests_test.py：

```python
import requests

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36",
}

headers = {

    'Cookie':'PSTM=1709092349; BIDUPSID=D5B6C55DD77CC7EA25017DFA56C8DD20; BAIDUID=B16CDF290DF41E6271B19104FEF2C03F:SL=0:NR=10:FG=1; BDUSS=d1TWJxdndWdWpYekFpdkRvYkx0akFNb3BmbzJrMTVDLS1WN1BlVWVVaTdVbXRuRVFBQUFBJCQAAAAAAAAAAAEAAAAe9iQmbWFfeGluZ2tvbmcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALvFQ2e7xUNnVV; BDUSS_BFESS=d1TWJxdndWdWpYekFpdkRvYkx0akFNb3BmbzJrMTVDLS1WN1BlVWVVaTdVbXRuRVFBQUFBJCQAAAAAAAAAAAEAAAAe9iQmbWFfeGluZ2tvbmcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALvFQ2e7xUNnVV; BD_UPN=12314753; H_WISE_SIDS_BFESS=110085_633619_640445_640315_638940_638945_638938_641044_641048_641125_641118_641115_641123_641113_641188_641192_641191_641311_640864_641139; MAWEBCUID=web_sTtEbPlpECKdpCPDgMxjveFocQSZAxUzMoZpUWXnWavbjorMmF; sug=3; sugstore=1; ORIGIN=0; bdime=0; H_WISE_SIDS=61027_61669_62054_62063_62114_62128_62169_62176_62184_62186_62182; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; ab_sr=1.0.1_MDc3M2FhN2RkZWQ1ZDMzZDBkNjI0OGUzNzZkMTBkODI5YzUxNmY0NTVjYTYzYmI2YTBmMWI5NjUyOTZiYmViODIyNzI1MzI1M2NlYjA5NzYwNzczZDMxNGNhMmZiNWU4ZThlOGM0ZDhlNDkxOGZiMWUyYTY0NjY4OTkwNzU1NGZjNTJlMWFhOGMzZmVlOWZlZGM2MjRhMzc5ZDQyMjJkZjY4MWVlZjViN2UyMGRmNGI5MDhjYmE4MDk5M2Y2MzU3OTkzOWU1MTRmNzU3MWFmNGFmMjEwZTgwNzAyODZhZTU=; H_PS_PSSID=61027_61669_62054_62063_62114_62128_62169_62176_62184_62186_62182; BAIDUID_BFESS=B16CDF290DF41E6271B19104FEF2C03F:SL=0:NR=10:FG=1; BA_HECTOR=8kagal0kag2haka02l842h0h86tt161jrd41d1v; ZFY=9NXaDeFmOtjI6IylKqxLUoM6kUKkFo4WjRMHW:B:Ay4Ts:C',
    'Home': 'www.baidu.com',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
}

res = requests.request('GET','https://www.baidu.com', headers=headers)
print(res.content.decode("utf-8"))
```

携带cookie的情况：

weibo_login_savecookie.py：

```python
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
import time
import json

def prelogin():
    # 1. 创建浏览器打开需要自动登录的网页
    chrome_driver = 'C:\Program Files\Google\Chrome\Application\chromedriver-win64\chromedriver.exe'
    service = Service(executable_path=chrome_driver)
    driver = webdriver.Chrome(service=service)
    driver.get('https://weibo.com/login.php')

    # 2. 留足够长的时间给人工完成登录
    # （完成登录的时候必须保证浏览器对象指向的窗口能够看到登录成功的效果）

    # 进入网页后会有登录提示，手动扫码登录成功后，回到pycharm的输出区输入任意
    # 字符给input，方便我们知道执行到什么地方了
    input('已经完成登录:')

    # 3. 获取浏览器cookie保存到本地文件
    cookies = driver.get_cookies()
    with open('weibo_cookie.txt', 'w', encoding='utf-8') as f:
        f.write(json.dumps(cookies))


def login():
    chrome_driver = 'C:\Program Files\Google\Chrome\Application\chromedriver-win64\chromedriver.exe'
    service = Service(executable_path=chrome_driver)
    driver = webdriver.Chrome(service=service)
    driver.get('https://www.weibo.com')
    time.sleep(4)
    # 1. 从本地的cookie文件中获取cookie
    with open('weibo_cookie.txt', encoding='utf-8') as f:
        listCookies = json.loads(f.read())

    # 2. 添加cookie
    driver.delete_all_cookies()
    for cookie in listCookies:
        driver.add_cookie(cookie)

    # 3.重新打开网页
    driver.get("https://www.weibo.com")
    input()

if __name__ == '__main__':
    # prelogin()
    login()
```

对于一些翻页的情况，对应游览器开发者工具中网络的fetch/xhr：

ajax_weibo_2025.py：

```python
# _*_ coding=utf-8 _*_
import requests
from urllib.parse import urlencode
base_url = 'https://weibo.com/ajax/feed/hottimeline?'
headers = {
    'Cookie':'SINAGLOBAL=1092703541748.4677.1709092275180; UOR=,,www.baidu.com; SCF=AtVFjUjuFca61vi20j3CjGsz-IOcDXSe0rccGmwzIbWO4OF7HWHxWLYuBKdijId5mbff9p9Gd0TRsHKUd6saixA.; SUBP=0033WrSXqPxfM72wWs9jqgMF55529P9D9WFR7GHRsBwpWJFfIK2ows1N5JpV2sfRIcvV9XWrdg8DdF4odcXt; SUB=_2AkMRA4KMdcPxrAFTm_4SyGzna41H-jyi1ut6An7uJhMyAxh37lcrqSVutBF-XDLCrc1NlYjO3d7BsbGtPjY_1r2a; ULV=1719584395797:7:2:1:6346079293901.104.1719584395795:1717505492391; XSRF-TOKEN=YrhGjFokxkAfUhzr4rHPSlqc; WBPSESS=Dt2hbAUaXfkVprjyrAZT_BoSXWkQ3N-EdBSOBUMw_bJyjftBbuVz-6m9kQVMvh6KdJY-wk8ctRh-oztFNAVkjF5B5Z0TAhBVdmoo63T6gXg0vYn66Zo-j5fE-fVlzb7Eavu_8johA_ZFFYKppvkT_w==',
    'Referer': 'https://weibo.com/newlogin?tabtype=weibo&gid=102803&openLoginLayer=0&url=https%3A%2F%2Fweibo.com%2F',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',
    'X-Requested-With': 'XMLHttpRequest',
    'X-Xsrf-Token':'YrhGjFokxkAfUhzr4rHPSlqc',
}
def get_page(page):
    params = {
        'refresh': '2',
        'group_id': '102803',
        'containerid': '102803',
        'extparam': 'discover|new_feed',
        'max_id': page,
        'count': 10
    }
    url = base_url + urlencode(params)
    print(url)
    try:
        res = requests.get(url, headers=headers)
        if res.status_code == 200:
            print(res.content.decode('utf-8','ignore'))
    except Exception as e:
        print('Error:', e.args)
if __name__ == "__main__":
    for page in range(1, 5):
        result = get_page(page)
```

### 2.2 游览器模拟

Selenium

### 2.3 API

服务平台提供，存在的问题：请求限制（次数，范围）



## 3.采集工具试用

### 3.1 后裔采集器

### 3.2 Selenium

WebDriver 使用浏览器供应商提供的浏览器自动化 API 来控制浏览器和运行测试



## 4.爬虫与反爬虫