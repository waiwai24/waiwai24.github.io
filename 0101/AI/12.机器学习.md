# 机器学习

## 1.学习形式

学习：让 Agent 能应对真实的场景，通过学习修改 Agent 的决策行为，提高性能

学习需要考虑的四个要素：

* 要改进 Agent 的哪个部件
  * 条件到动作的直接映射
  * 从感知序列推演状态的映射
  * 动作转移函数
  * 效用函数
  * 动作代价函数
* 学习具备哪些先验知识
  * 归纳学习：从特定的输入输出对中学习一般化的函数和规则，逻辑上并不可靠
  * 分析学习或演绎学习：从已知规则出发，推理出其逻辑蕴含的新规则，提高系统处理的效率
* 数据和你学习改进的部件如何表示
* 用于学习的反馈有哪些
  * 无监督学习：不提供显式反馈，Agent 学习输入中的模式，目标是发现输入数据的关联或规律，输出往往是数据的另一种表示，例如：聚类
  * 监督学习：Agent 观察某些“输入-输出”对，学习从输入到输出的映射函数，以“输出”作为“输入”的反馈输出是什么取决于学习任务是什么，类比“有参考答案的学习”
  * 强化学习：Agent 在强化序列（奖赏和惩罚组合的序列）中学习，反馈是当前与预期结果的差异，根据对局过程改进博弈，类比在“实践中学习”

## 2.监督学习

最简单的形式：从例子中学习映射函数

𝑓 为学习的目标函数：分类（输出 y 的值域是有限集合，最简单的二分类是输出两个可能值）；回归（输出 y 的值域是连续数值的集合）

样例： (𝑥1, 𝑦1), (𝑥2, 𝑦2), …, (𝑥_𝑛, 𝑦_𝑛)，满足函数 y = 𝑓(𝑥) 

目标：找到一个函数 ℎ, 使得 ℎ 尽可能逼近 𝑓

由于我们不知道真实函数，所以我们并不总能确定给定的学习问题是否可实现

假说空间 H：用于逼近 𝑓 的一组函数集合，例如，𝐬𝐢𝐧⁡(𝒘𝒙), 𝒂𝒙𝟓+𝒃𝒙𝟐+𝒄𝒙+𝒅

训练集：用于求解 𝒉

测试集：用于评测求解得到的 𝒉

泛化：能够对新的样例进行预测

奥坎姆剃刀：如无必要，勿增实体。如果两个或多个处于竞争地位的理论能得出同样的结论，那么简单或可证伪的那个更好

## 3.学习决策树

### 3.1 决策树

* 输入：属性值向量
* 输出：决策（分类）结果
* 输入和输出可以是离散的，也可以是连续的

### 3.2 从样例归纳决策树

基本思想：

* 贪婪+分治+递归
* 总是优先测试最重要属性，将该属性的测试作为当前问题的决策树的根
* 对该属性的测试将问题分解成更小的子问题
* 递归解决子问题，构建子决策树

### 3.3 选择测试属性

* 熵是随机变量的不确定性度量，信息增加导致熵的减少
* 设随机变量 𝑽 的取值为 𝒗𝒌 的概率为 𝑷(𝒗𝒌)，则 𝑽 的熵为 $H(V)=\sum_kP(v_i)\mathrm{log}_2\frac1{P(v_i)}=-\sum_kP(v_i)\mathrm{log}_2P(v_i)$
* 设布尔随机变量以 𝒒 的概率为真，则该变量的熵为 $B(q)=-(q\log_2q+(1-q)\log_2(1-q))$
* 如果训练集包含 𝑝 个正例和 𝑛 个反例，则目标属性 𝐺𝑜𝑎𝑙 在整个样例集上的熵是 $H(Goal)=B\left(\frac p{p+n}\right)$
* 测试某个属性 𝐴 后，目标属性的熵会减少，减少的幅度可以作为选择测试属性的依据
* 例子：以公平(Fair)的方式抛掷一枚硬币，正面向上或反面向上（0 或者 1）的可能性近似相同：$H(Fair)=-(0.5\log_20.5+0.5\log_20.5)=1$

### 3.4 泛化与过度拟合

* 过度拟合：模型与训练数据的一致性高，但在测试数据上性能降低
* 当假说空间和属性数目增长时，过度拟合更可能出现，而随着训练样例的增加，过度拟合的可能性逐步降低
* 决策树剪枝：减轻对训练样例的过度拟合，删除不明显相关的节点来实现剪枝
