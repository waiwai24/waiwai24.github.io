# python 机器学习

## 1.基本概念

* 准确率（Accuracy）：所有的预测正确（正类负类）的占总的比重
* 精确率（Precision）：查准率。即正确预测为正的占全部预测为正的比例
* 召回率（Recall）：查全率。即正确预测为正的占全部实际为正的比例
* F1 值（H-mean 值）：F1 值为算数平均数除以几何平均数，且越大越好



## 2.Scikit-learn

Scikit-learn（简称 sklearn）是开源的 Python 机器学习库，它基于 Numpy 和 Scipy，包含大量数据挖掘和分析的工具，例如数据预处理、交叉验证、算法与可视化算法等

完成机器学习的步骤：

- 选择数据：将数据分成三组，分别是训练数据、验证数据和测试数据
- 模拟数据：使用训练数据来构建使用相关特征的模型
- 验证模型：使用验证数据接入模型
- 测试模型：使用测试数据检查被验证的模型的表现
- 使用模型：使用完全训练好的模型在新数据上做预测
- 调优模型：使用更多数据、不同的特征或调整过的参数来提升算法的性能表现



## 3.分类算法

- 决策树：
  - 基于特征值构建树型决策结构，通过一系列 if-else 规则对数据进行分类
  - 优点：计算复杂度不高，输出结果易于理解，数据有缺失也能跑，可以处理不相关特征
  - 缺点：容易过拟合
  - 适用数据类型：数值型和标称型
- 支持向量机 SVM：
  - 通过寻找最优分离超平面来实现分类，最大化不同类别间的间隔
  - 优点：泛化（由具体的、个别的扩大为一般的，就是说：模型训练完后的新样本）错误率低，计算开销不大，结果易理解。
  - 缺点：对参数调节和核函数的选择敏感，原始分类器不加修改仅适合于处理二分类问题
  - 使用数据类型：数值型和标称型数据
- k-近邻算法：
  - 基于 "物以类聚" 思想，通过计算样本间距离，根据 K 个最近邻居的类别进行多数投票预测
  - 优点：精度高、对异常值不敏感、无数据输入假定
  - 缺点：计算复杂度高、空间复杂度高
  - 适用数据范围：数值型和标称型
- 贝叶斯网络：
  - 基于贝叶斯定理和特征条件独立假设，计算后验概率进行分类
  - 优点: 在数据较少的情况下仍然有效，可以处理多类别问题
  - 缺点: 对于输入数据的准备方式较为敏感
  - 适用数据类型: 标称型数据
- 随机森林：
  - 集成学习方法，通过构建多个决策树并结合它们的预测结果来提高整体性能
  - 优点：几乎不需要输入准备、可实现隐式特征选择、训练速度非常快、其他模型很难超越、很难建立一个糟糕的随机森林模型、大量优秀、免费以及开源的实现
  - 缺点：劣势在于模型大小、是个很难去解释的黑盒子
  - 适用数据范围：数值型和标称型